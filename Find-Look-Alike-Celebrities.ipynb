{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'import ray\\nray.init(plasma_directory=\"/workspaces/96273/temp\")\\nimport modin.pandas as pd'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation\n",
    "from keras.layers import Conv2D, AveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras import metrics\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from extract_face_landmarks.py import extract_face_landmarks\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "from skimage.filters import sobel\n",
    "\"\"\"import ray\n",
    "ray.init(plasma_directory=\"/workspaces/96273/temp\")\n",
    "import modin.pandas as pd\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you have multiple GPUs, use this block to avoid allocate all GPUs and all memory.\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG-Face for face recognition: https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/\n",
    "\n",
    "def loadVggFaceModel():\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(2622, (1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)\n",
    "    \n",
    "    return vgg_face_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadVggFaceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can download pretrained weights from https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "from keras.models import model_from_json\n",
    "model.load_weights('vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open-cv's face detection module\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/\n",
    "# https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_crop.tar\n",
    "mat = scipy.io.loadmat('imdb_crop/imdb.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"dob\", \"photo_taken\", \"full_path\", \"gender\", \"name\", \"face_location\", \"face_score\", \"second_face_score\", \"celeb_names\", \"celeb_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = mat['imdb'][0][0][0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index = range(0,instances), columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460723, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mat:\n",
    "    if i == \"imdb\":\n",
    "        current_array = mat[i][0][0]\n",
    "        for j in range(len(current_array)):\n",
    "            #print(j,\". \",columns[j],\": \",current_array[j][0])\n",
    "            df[columns[j]] = pd.DataFrame(current_array[j][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dob</th>\n",
       "      <th>photo_taken</th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>face_location</th>\n",
       "      <th>face_score</th>\n",
       "      <th>second_face_score</th>\n",
       "      <th>celeb_names</th>\n",
       "      <th>celeb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm124825600_1899-5-10_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[1072.926, 161.838, 1214.7839999999999, 303.6...</td>\n",
       "      <td>1.459693</td>\n",
       "      <td>1.118973</td>\n",
       "      <td>['Lee' George Quinones]</td>\n",
       "      <td>6488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>693726</td>\n",
       "      <td>1970</td>\n",
       "      <td>[01/nm0000001_rm3343756032_1899-5-10_1970.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[477.184, 100.352, 622.592, 245.76]]</td>\n",
       "      <td>2.543198</td>\n",
       "      <td>1.852008</td>\n",
       "      <td>['Weird Al' Yankovic]</td>\n",
       "      <td>6488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm577153792_1899-5-10_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[114.96964308962852, 114.96964308962852, 451....</td>\n",
       "      <td>3.455579</td>\n",
       "      <td>2.985660</td>\n",
       "      <td>[2 Chainz]</td>\n",
       "      <td>6488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm946909184_1899-5-10_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[622.8855056426588, 424.21750383700805, 844.3...</td>\n",
       "      <td>1.872117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[50 Cent]</td>\n",
       "      <td>6488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>693726</td>\n",
       "      <td>1968</td>\n",
       "      <td>[01/nm0000001_rm980463616_1899-5-10_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[Fred Astaire]</td>\n",
       "      <td>[[1013.8590023603723, 233.8820422075853, 1201....</td>\n",
       "      <td>1.158766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[A Martinez]</td>\n",
       "      <td>6488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dob  photo_taken                                       full_path  \\\n",
       "0  693726         1968   [01/nm0000001_rm124825600_1899-5-10_1968.jpg]   \n",
       "1  693726         1970  [01/nm0000001_rm3343756032_1899-5-10_1970.jpg]   \n",
       "2  693726         1968   [01/nm0000001_rm577153792_1899-5-10_1968.jpg]   \n",
       "3  693726         1968   [01/nm0000001_rm946909184_1899-5-10_1968.jpg]   \n",
       "4  693726         1968   [01/nm0000001_rm980463616_1899-5-10_1968.jpg]   \n",
       "\n",
       "   gender            name                                      face_location  \\\n",
       "0     1.0  [Fred Astaire]  [[1072.926, 161.838, 1214.7839999999999, 303.6...   \n",
       "1     1.0  [Fred Astaire]              [[477.184, 100.352, 622.592, 245.76]]   \n",
       "2     1.0  [Fred Astaire]  [[114.96964308962852, 114.96964308962852, 451....   \n",
       "3     1.0  [Fred Astaire]  [[622.8855056426588, 424.21750383700805, 844.3...   \n",
       "4     1.0  [Fred Astaire]  [[1013.8590023603723, 233.8820422075853, 1201....   \n",
       "\n",
       "   face_score  second_face_score              celeb_names  celeb_id  \n",
       "0    1.459693           1.118973  ['Lee' George Quinones]      6488  \n",
       "1    2.543198           1.852008    ['Weird Al' Yankovic]      6488  \n",
       "2    3.455579           2.985660               [2 Chainz]      6488  \n",
       "3    1.872117                NaN                [50 Cent]      6488  \n",
       "4    1.158766                NaN             [A Martinez]      6488  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove pictures does not include face\n",
    "df = df[df['face_score'] != -np.inf]\n",
    "\n",
    "#some pictures include more than one face, remove them\n",
    "df = df[df['second_face_score'].isna()]\n",
    "\n",
    "#check threshold\n",
    "df = df[df['face_score'] >= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95234, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #95234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractNames(name):\n",
    "    return name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['celebrity_name'] = df['name'].apply(extractNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95234, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(columns = ['dob', 'photo_taken', 'face_location', 'face_score', 'second_face_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImagePixels(image_path):\n",
    "    return cv2.imread(\"imdb_crop/%s\" % image_path[0]) #pixel values in scale of 0-255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "df['pixels'] = df['full_path'].apply(getImagePixels)\n",
    "toc = time.time()\n",
    "\n",
    "print(\"this block completed in \",toc-tic,\" seconds...\") #562.80 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Represent images as vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = {}\n",
    "def findFaceRepresentation(img):\n",
    "    detected_face = img\n",
    "    #plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    #-----------------------------\n",
    "    \"\"\"\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        detected_face = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "\n",
    "        try:\n",
    "            margin = 10\n",
    "            margin_x = int((w * margin)/100); margin_y = int((h * margin)/100)\n",
    "            detected_face = img[int(y-margin_y):int(y+h+margin_y), int(x-margin_x):int(x+w+margin_x)]\n",
    "        except:\n",
    "            print(\"detected face has no margin\")\n",
    "    \"\"\"\n",
    "    #-----------------------------\n",
    "    \n",
    "    try: \n",
    "        detected_face = cv2.resize(detected_face, (224, 224))\n",
    "        #plt.imshow(cv2.cvtColor(detected_face, cv2.COLOR_BGR2RGB))\n",
    "        features = extract_face_landmarks(img[int(y):int(y+h), int(x):int(x+w)])\n",
    "        left_eye = features[0]\n",
    "        right_eye = features[1]\n",
    "        mouth = features[2]\n",
    "        nose = features[3]\n",
    "        img = color.rgb2gray(img)\n",
    "        features_list['original'] = {}\n",
    "        features_list['original']['le'] = img[left_eye[0], left_eye[1]]\n",
    "        features_list['original']['re'] = img[right_eye[0], right_eye[1]]\n",
    "        features_list['original']['mo'] = img[mouth[0], mouth[1]]\n",
    "        features_list['original']['no'] = img[nose[0], nose[1]]\n",
    "        img_s = sobel(img)\n",
    "        features_list['original'] = {}\n",
    "        features_list['original']['ele'] = img_s[left_eye[0], left_eye[1]]\n",
    "        features_list['original']['ere'] = img_s[right_eye[0], right_eye[1]]\n",
    "        features_list['original']['emo'] = img_s[mouth[0], mouth[1]]\n",
    "        features_list['original']['eno'] = img_s[nose[0], nose[1]]\n",
    "        \n",
    "        #normalize detected face in scale of -1, +1\n",
    "\n",
    "        img_pixels = image.img_to_array(detected_face)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels /= 127.5\n",
    "        img_pixels -= 1\n",
    "        \n",
    "        representation = model.predict(img_pixels)[0,:]\n",
    "    except:\n",
    "        representation = None\n",
    "        \n",
    "    return representation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "df['face_vector_raw'] = df['pixels'].apply(findFaceRepresentation) #vector for raw image\n",
    "toc = time.time()\n",
    "\n",
    "print(\"this block completed in \",toc-tic,\" seconds...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Your Photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"sefik.jpg\") #pixel values in scale of 0-255\n",
    "#img = cv2.imread(\"sefik_2.jpg\") #pixel values in scale of 0-255\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "faces_landmarks = {}\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    detected_face = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "    features = extract_face_landmarks(img[int(y):int(y+h), int(x):int(x+w)])\n",
    "    left_eye = features[0]\n",
    "    right_eye = features[1]\n",
    "    mouth = features[2]\n",
    "    nose = features[3]\n",
    "    img = color.rgb2gray(img)\n",
    "    features_list['load'] = {}\n",
    "    features_list['load']['le'] = img[left_eye[0], left_eye[1]]\n",
    "    features_list['load']['re'] = img[right_eye[0], right_eye[1]]\n",
    "    features_list['load']['mo'] = img[mouth[0], mouth[1]]\n",
    "    features_list['original']['no'] = img[nose[0], nose[1]]\n",
    "    img_s = sobel(img)\n",
    "    features_list['load'] = {}\n",
    "    features_list['load']['ele'] = img_s[left_eye[0], left_eye[1]]\n",
    "    features_list['load']['ere'] = img_s[right_eye[0], right_eye[1]]\n",
    "    features_list['load']['emo'] = img_s[mouth[0], mouth[1]]\n",
    "    features_list['load']['eno'] = img_s[nose[0], nose[1]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #cv2.rectangle(img,(x,y),(x+w,y+h),(128,128,128),cv2.FILLED)\n",
    "    #plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    #add 15% margin around the face\n",
    "    try:\n",
    "        margin = 10\n",
    "        margin_x = int((w * margin)/100); margin_y = int((h * margin)/100)\n",
    "        detected_face = img[int(y-margin_y):int(y+h+margin_y), int(x-margin_x):int(x+w+margin_x)]\n",
    "    except:\n",
    "        print(\"detected face has no margin\")\n",
    "    \n",
    "    detected_face = cv2.resize(detected_face, (224, 224))\n",
    "\n",
    "#plt.imshow(detected_face)\n",
    "#plt.imshow(cv2.cvtColor(detected_face, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pixels = image.img_to_array(detected_face)\n",
    "img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "img_pixels /= 127.5\n",
    "img_pixels -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yourself_representation = model.predict(img_pixels)[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCosineSimilarity(source_representation, test_representation=yourself_representation):\n",
    "    try:\n",
    "        a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "        b = np.sum(np.multiply(source_representation, source_representation))\n",
    "        c = np.sum(np.multiply(test_representation, test_representation))\n",
    "        return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    "    except:\n",
    "        return 10 #assign a large value. similar faces will have small value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findScore():\n",
    "    loss = 0\n",
    "    for i in features_list['original'].keys():\n",
    "        loss = np.sum(np.abs(features_list['original'][i] - features_list['load'][i]))\n",
    "    return loss/(len(features_list['original'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['similarity'] = df['face_vector_raw'].apply(findCosineSimilarity)\n",
    "print(findScore())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['similarity'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"x = df.iloc[0]['pixels'].reshape(224, 224, 3)/255\n",
    "plt.imshow(x)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this block might show different pictures of same actors\n",
    "if True:\n",
    "    for i in range(0, 7):\n",
    "        instance = df.iloc[i]\n",
    "        name = instance['celebrity_name']\n",
    "        similarity = instance['similarity']\n",
    "        \n",
    "        #img = instance['pixels']\n",
    "        full_path = instance['full_path'][0]\n",
    "        img = cv2.imread(\"imdb_crop/%s\" % full_path)\n",
    "        \n",
    "        print(i,\".\",name,\" (\",similarity,\") - \",full_path)\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "\n",
    "        print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = df.drop_duplicates(subset =\"celebrity_name\")\n",
    "pivot_df = pivot_df[pivot_df['photo_taken'] >= 2000]\n",
    "\n",
    "#0: woman, 1: man. if you know the gender of your target image, then you can filter data set and it fasten system\n",
    "pivot_df = pivot_df[pivot_df['gender'] == 1]\n",
    "\n",
    "pivot_df = pivot_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, 4):\n",
    "    instance = pivot_df.iloc[i]\n",
    "    name = instance['celebrity_name']\n",
    "    similarity = instance['similarity']\n",
    "    \n",
    "    similarity = (1 - similarity)*100\n",
    "    \n",
    "    #img = instance['pixels']\n",
    "    full_path = instance['full_path'][0]\n",
    "    img = cv2.imread(\"imdb_crop/%s\" % full_path)\n",
    "    \n",
    "    print(name,\" (\",similarity,\"%) - \",full_path)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can check a specific celebrity\n",
    "target = pivot_df[pivot_df['celebrity_name'] == 'Jim Parsons']\n",
    "\n",
    "for index, instance in target.iterrows():\n",
    "    name = instance['celebrity_name']\n",
    "    similarity = instance['similarity']\n",
    "    full_path = instance['full_path'][0]\n",
    "\n",
    "    similarity = (1 - similarity)*100\n",
    "    \n",
    "    print(index,\". \", name,\" (\",similarity,\") - \",full_path)\n",
    "\n",
    "    img = cv2.imread(\"imdb_crop/%s\" % full_path)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
